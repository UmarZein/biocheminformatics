{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3202a7b-94f8-4172-8526-ed1aa9b07e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import DimeNet, DimeNetPlusPlus\n",
    "\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument('--use_dimenet_plus_plus', action='store_true')\n",
    "#args = parser.parse_args()\n",
    "use_dimenet_plus_plus=False\n",
    "\n",
    "Model = DimeNetPlusPlus if use_dimenet_plus_plus else DimeNet\n",
    "\n",
    "path = 'datasets'#osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', 'QM9')\n",
    "dataset = QM9(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "607dda3e-780c-4e1f-879f-646d1a3278a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method atomref in module torch_geometric.datasets.qm9:\n",
      "\n",
      "atomref(target: int) -> Optional[torch.Tensor] method of torch_geometric.datasets.qm9.QM9 instance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(dataset.atomref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e907370d-ce41-4982-945f-24105338dd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\umarzein\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m model, datasets \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_qm9_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m train_dataset, val_dataset, test_dataset \u001b[38;5;241m=\u001b[39m datasets\n\u001b[0;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch_geometric\\nn\\models\\dimenet.py:579\u001b[0m, in \u001b[0;36mDimeNet.from_qm9_pretrained\u001b[1;34m(cls, root, dataset, target)\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a pre-trained :class:`DimeNet` model on the\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;124;03m:class:`~torch_geometric.datasets.QM9` dataset, trained on the\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;124;03mspecified target :obj:`target`.\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    578\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTF_CPP_MIN_LOG_LEVEL\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 579\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m target \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m target \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m target \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[0;32m    583\u001b[0m root \u001b[38;5;241m=\u001b[39m osp\u001b[38;5;241m.\u001b[39mexpanduser(osp\u001b[38;5;241m.\u001b[39mnormpath(root))\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "\n",
    "# DimeNet uses the atomization energy for targets U0, U, H, and G, i.e.:\n",
    "# 7 -> 12, 8 -> 13, 9 -> 14, 10 -> 15\n",
    "idx = torch.tensor([0, 1, 2, 3, 4, 5, 6, 12, 13, 14, 15, 11])\n",
    "dataset.data.y = dataset.data.y[:, idx]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for target in range(12):\n",
    "    # Skip target \\delta\\epsilon, since it can be computed via\n",
    "    # \\epsilon_{LUMO} - \\epsilon_{HOMO}:\n",
    "    if target == 4:\n",
    "        continue\n",
    "\n",
    "    model, datasets = Model.from_qm9_pretrained(path, dataset, target)\n",
    "    train_dataset, val_dataset, test_dataset = datasets\n",
    "\n",
    "    model = model.to(device)\n",
    "    loader = DataLoader(test_dataset, batch_size=256)\n",
    "\n",
    "    maes = []\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(data.z, data.pos, data.batch)\n",
    "        mae = (pred.view(-1) - data.y[:, target]).abs()\n",
    "        maes.append(mae)\n",
    "\n",
    "    mae = torch.cat(maes, dim=0)\n",
    "\n",
    "    # Report meV instead of eV:\n",
    "    mae = 1000 * mae if target in [2, 3, 4, 6, 7, 8, 9, 10] else mae\n",
    "\n",
    "    print(f'Target: {target:02d}, MAE: {mae.mean():.5f} Â± {mae.std():.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd49dbfc-d020-4d70-939d-a082120b92c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
