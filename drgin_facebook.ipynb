{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import degree, scatter\n",
    "from torch_geometric.nn.norm import GraphNorm\n",
    "from torch_geometric.nn import MessagePassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'get_default_device'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Check current default device\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_device\u001b[49m())\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\__init__.py:1938\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m   1935\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[0;32m   1936\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m-> 1938\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'get_default_device'"
     ]
    }
   ],
   "source": [
    "# Check current default device\n",
    "print(torch.get_default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_default_device('cuda')\n",
    "# print(torch.get_default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    if not hasattr(data, 'pos') or data.pos is None:\n",
    "        data.pos = torch.rand((data.num_nodes, 2)) * 100.0\n",
    "    if not hasattr(data, 'atom_type') or data.atom_type is None:\n",
    "        deg = degree(data.edge_index[0], num_nodes=data.num_nodes).long()\n",
    "        data.atom_type = (deg % 200)\n",
    "    if data.y is not None:\n",
    "        data.y = data.y.float()\n",
    "    else:\n",
    "        data.y = torch.tensor([0.0])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, dropout_rate=0.0, final_activation=None):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = in_channels\n",
    "        for hidden in hidden_channels:\n",
    "            layers.append(nn.Linear(prev, hidden))\n",
    "            layers.append(nn.ReLU())\n",
    "            if dropout_rate > 0:\n",
    "                layers.append(nn.Dropout(dropout_rate))\n",
    "            prev = hidden\n",
    "        layers.append(nn.Linear(prev, out_channels))\n",
    "        if final_activation is not None:\n",
    "            layers.append(final_activation)\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        for m in self.net:\n",
    "            if hasattr(m, 'reset_parameters'):\n",
    "                m.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGINConv(MessagePassing):\n",
    "    def __init__(\n",
    "        self,\n",
    "        mlp_dims_node: list,\n",
    "        mlp_dims_edge: list,\n",
    "        aggr: str = 'sum',\n",
    "        dropout_rate: float = 0.0,\n",
    "    ):\n",
    "        super().__init__(node_dim=0, aggr=aggr)\n",
    "        self.node_dimses = mlp_dims_node\n",
    "        self.edge_dimses = mlp_dims_edge\n",
    "        self.aggr = aggr\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.node_mlp = nn.ModuleList([\n",
    "            MLP(mlp_dims_node[0], mlp_dims_node[1:-1], mlp_dims_node[-1],\n",
    "                final_activation=None, dropout_rate=dropout_rate)\n",
    "            for _ in range(mlp_dims_edge[-1])\n",
    "        ])\n",
    "        self.edge_mlp = MLP(mlp_dims_edge[0], mlp_dims_edge[1:-1], mlp_dims_edge[-1],\n",
    "                            dropout_rate=dropout_rate, final_activation=None)\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        for m in self.node_mlp:\n",
    "            m.reset_parameters()\n",
    "        self.edge_mlp.reset_parameters()\n",
    "        \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "        \n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'mlp_dims_node': self.node_dimses,\n",
    "            'mlp_dims_edge': self.edge_dimses,\n",
    "            'aggr': self.aggr,\n",
    "            'dropout_rate': self.dropout_rate,\n",
    "        }\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, edge_index, edge_attr: torch.Tensor, edge_weight=None):\n",
    "        # Proses edge_attr melalui MLP dan softmax-kan di sepanjang dim terakhir\n",
    "        edge_attr = self.edge_mlp(edge_attr).softmax(-1)\n",
    "        if edge_weight is not None:\n",
    "            edge_attr = edge_attr * edge_weight\n",
    "        size = (x.size(0), x.size(0))\n",
    "        out = torch.zeros(x.size(0), self.node_dimses[-1], device=x.device)\n",
    "        \n",
    "        for edge_idx in range(self.edge_dimses[-1]):\n",
    "            h = self.propagate(edge_index, edge_attr=edge_attr, x=x, size=size, edge_idx=edge_idx)\n",
    "            h2 = self.node_mlp[edge_idx](h)\n",
    "            out = out + h2\n",
    "        return out\n",
    "    \n",
    "    def message(self, x_j: torch.Tensor, edge_attr, edge_idx) -> torch.Tensor:\n",
    "        return x_j * edge_attr[:, edge_idx].unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radius_interaction_graph(pos, batch, cutoff=10.0, max_neighbors=32):\n",
    "    N, _ = pos.size()\n",
    "    edge_index = [[], []]\n",
    "    edge_weight = []\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i == j:\n",
    "                continue\n",
    "            d = torch.norm(pos[i] - pos[j], p=2).item()\n",
    "            if d <= cutoff:\n",
    "                edge_index[0].append(i)\n",
    "                edge_index[1].append(j)\n",
    "                edge_weight.append(d)\n",
    "    if len(edge_weight) == 0:\n",
    "        edge_index = torch.tensor([[0], [0]], dtype=torch.long)\n",
    "        edge_weight = torch.tensor([cutoff], dtype=torch.float)\n",
    "    else:\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "        edge_weight = torch.tensor(edge_weight, dtype=torch.float)\n",
    "    return edge_index, edge_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRGIN5(nn.Module):\n",
    "    def __init__(self, \n",
    "                 node_dimses, \n",
    "                 edge_dimses, \n",
    "                 dropout_rate=0.0,\n",
    "                 cutoff=10.0,\n",
    "                 max_neighbors=32,\n",
    "                 aggr: str = 'sum'):\n",
    "        super().__init__()\n",
    "        self.rgins = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "        self.atom_type_emb = nn.Embedding(200, node_dimses[0][0])\n",
    "        self.cutoff = cutoff\n",
    "        self.max_neighbors = max_neighbors\n",
    "        self.dist_norm = GraphNorm(1)\n",
    "        \n",
    "        for mlp_dims_node, mlp_dims_edge in zip(node_dimses, edge_dimses):\n",
    "            self.rgins.append(RGINConv(mlp_dims_node, mlp_dims_edge, dropout_rate=dropout_rate, aggr=aggr))\n",
    "            self.norms.append(GraphNorm(mlp_dims_node[-1]))\n",
    "            \n",
    "        self.node_dimses = node_dimses \n",
    "        self.edge_dimses = edge_dimses \n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.aggr = aggr\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        for rgin in self.rgins:\n",
    "            rgin.reset_parameters()\n",
    "            \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "        \n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'node_dimses': self.node_dimses,\n",
    "            'edge_dimses': self.edge_dimses,\n",
    "            'dropout_rate': self.dropout_rate,\n",
    "            'cutoff': self.cutoff,\n",
    "            'max_neighbors': self.max_neighbors,\n",
    "            'aggr': self.aggr,\n",
    "        }\n",
    "    \n",
    "    def forward(self, data):\n",
    "        edge_index, edge_weight = radius_interaction_graph(data.pos, data.batch,\n",
    "                                                           cutoff=self.cutoff,\n",
    "                                                           max_neighbors=self.max_neighbors)\n",
    "        #edge_index=edge_index.to(device)\n",
    "        #edge_weight=edge_weight.to(device)\n",
    "        if data.batch is not None:\n",
    "            print(\"edge_weight:\",edge_weight)\n",
    "            print(\"data.batch[edge_index[0]]:\",data.batch[edge_index[0]])\n",
    "            edge_attr = self.dist_norm(edge_weight.unsqueeze(-1), data.batch[edge_index[0]])\n",
    "        else:\n",
    "            edge_attr = self.dist_norm(edge_weight.unsqueeze(-1), torch.zeros_like(edge_index[0]).long())\n",
    "        edge_weight = ((self.cutoff + 1) - edge_weight.unsqueeze(-1)) / (self.cutoff + 1)\n",
    "        \n",
    "        h = self.atom_type_emb(data.atom_type)\n",
    "        \n",
    "        for i, (rgin, norm) in enumerate(zip(self.rgins, self.norms)):\n",
    "            h = rgin(h, edge_index, edge_attr, edge_weight=edge_weight)\n",
    "            if i + 1 < len(self.rgins):\n",
    "                h = norm(h, batch=data.batch)\n",
    "                h = torch.tanh(h)\n",
    "        if data.batch is not None:\n",
    "            h = scatter(h, data.batch, dim=0, reduce='mean').mean(-1)\n",
    "        else:\n",
    "            h = h.mean((-2, -1))\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. download dat raw\n",
    "2. process\n",
    "3. taro di folder processed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/BZR_MD.zip\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah graph: 306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = TUDataset(root='./data/TUDataset', name='BZR_MD')\n",
    "short_dataset = dataset[:1]\n",
    "print(f\"Jumlah graph: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch_geometric.datasets.tu_dataset.TUDataset"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TUDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#node feature -> atom type -> default value (0)\n",
    "#edge feature -> interatomic distance -> default value (0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"./datasets/instagram/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(edge_index=[2, 342], x=[19, 8], edge_attr=[342, 5], y=[1], batch=[19], ptr=[2])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 - Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(short_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "node_dimses = [[32, 64, 64]]\n",
    "edge_dimses = [[1, 16, 3]]\n",
    "model = DRGIN5(node_dimses, edge_dimses, dropout_rate=0.1, cutoff=10.0, max_neighbors=32, aggr='sum')\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "model.train()\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        break\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(batch)\n",
    "        loss = criterion(pred, batch.y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "    avg_loss = total_loss / len(short_dataset)\n",
    "    print(f\"Epoch {epoch+1:02d} - Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0 - mean.index_select(0, batch) * self.mean_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "sample = next(iter(loader)).to(device)\n",
    "with torch.no_grad():\n",
    "    pred_sample = model(sample)\n",
    "print(\"Prediksi nilai kontinu: \", pred_sample.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_graph_loss(model, dataset, device, criterion):\n",
    "    random_index = random.randint(0, len(dataset) - 1)\n",
    "    data = dataset[random_index]\n",
    "    \n",
    "    data = data.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(data)\n",
    "        \n",
    "    loss = criterion(output, data.y.view(-1))\n",
    "    \n",
    "    print(f\"Graph index: {random_index}\")\n",
    "    print(f\"Output model untuk graph ini: {output.cpu().numpy()}\")\n",
    "    print(f\"Loss untuk graph ini: {loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
