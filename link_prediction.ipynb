{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed5f96ed-6c3e-46ff-b095-041a59ed58c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from torch_geometric.data import Data, DataListLoader, Dataset, InMemoryDataset, Batch\n",
    "from torch_geometric.loader import DataListLoader, DataLoader\n",
    "from torch_geometric.nn import *\n",
    "from torch_geometric.utils import to_dense_adj, to_dense_batch, add_self_loops, remove_self_loops\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "import torch\n",
    "from torch import nn\n",
    "import rdkit\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "from rdkit import Chem\n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import RDLogger\n",
    "\n",
    "from copy import deepcopy\n",
    "#from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Tuple, List, Dict, Union\n",
    "from torch import Tensor\n",
    "from torch_geometric.nn import MessagePassing, radius_graph\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from torch_scatter import scatter\n",
    "from torch_geometric.typing import (\n",
    "    Adj,\n",
    "    OptTensor,\n",
    "    SparseTensor,\n",
    "    pyg_lib,\n",
    "    torch_sparse,\n",
    ")\n",
    "from torch_geometric.data import (\n",
    "    Data,\n",
    "    InMemoryDataset,\n",
    "    download_url,\n",
    "    extract_zip,\n",
    ")\n",
    "from rdkit import Chem\n",
    "import os\n",
    "# Suppress RDKit warnings\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "cuda=torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "import sascorer\n",
    "#torch.set_default_dtype(torch.float64)\n",
    "from models import *\n",
    "from rdkit.Chem.Crippen import MolLogP\n",
    "from typing import List\n",
    "from prolog import *\n",
    "import torchlens as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3615280-3685-4b3b-8ac4-247affaecf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import KarateClub\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "316e92e9-da73-4236-bb28-708bb3971419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import GNNBenchmarkDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eda1a3d-581c-40f6-afca-5be34345ffc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://data.pyg.org/datasets/benchmarking-gnns/PATTERN_v2.zip\n",
      "Extracting datasets\\gnnb-pattern\\PATTERN\\raw\\PATTERN_v2.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "ds=GNNBenchmarkDataset(\"datasets/gnnb-pattern\",name='PATTERN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1352e87f-ceec-42d8-8c4c-b2b37cbbe3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[108, 3], edge_index=[2, 4884], y=[108])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa2c72d1-7232-421a-aabd-2ff0d144ac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLinkPredictor(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCNLinkPredictor, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        # Two-layer GCN to compute node embeddings\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "    def decode(self, z, edge_index):\n",
    "        # Dot product decoder: returns a score for each edge\n",
    "        return (z[edge_index[0]] * z[edge_index[1]]).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fef7e79-bbd1-49dd-9beb-a789f5e79a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingContext:\n",
    "    def __init__(self, cls, *args, **kwargs):\n",
    "        self.inner = cls(*args, **kwargs).to(cuda)\n",
    "        self.name = cls.__name__\n",
    "        self.optim = torch.optim.AdamW(self.inner.parameters())\n",
    "        self.sched = torch.optim.lr_scheduler.ExponentialLR(self.optim, gamma=0.98)\n",
    "        self.num_parameters = sum(map(torch.numel,self.inner.parameters()))\n",
    "        self.train_loss_record = dict()\n",
    "        self.test_loss_record = dict()\n",
    "        self.results = list()\n",
    "        self.total_iters = 0\n",
    "        self.running_loss = 0\n",
    "        self.best_eval_loss = 999\n",
    "        self.stopped = False\n",
    "        self.batch_size=64\n",
    "        self.train_loss_metric='MSE'\n",
    "        self.eval_loss_metric='MAE'\n",
    "        self.last_target_name='link prediction'\n",
    "        self.last_dataset_name='GNN Benchmark: PATTERN'\n",
    "        self.training=True\n",
    "    def save(self, prefix='saves'):\n",
    "        save_model(\n",
    "            self.name,\n",
    "            self.inner,\n",
    "            optimizer=self.optim,\n",
    "            scheduler=self.sched,\n",
    "            loss_record={\n",
    "                'train':self.train_loss_record,\n",
    "                'test':self.test_loss_record,\n",
    "            },\n",
    "            total_training_iters=self.total_iters,\n",
    "            last_batch_size=self.batch_size,\n",
    "            loss_metric={\n",
    "                'train':'MSE',\n",
    "                'test':'MAE',\n",
    "            },\n",
    "            last_target_name=self.last_target_name,\n",
    "            last_dataset_name=self.last_dataset_name\n",
    "        )\n",
    "    @classmethod\n",
    "    def load(cls, name, class_, prefix='saves', training=False, override=None):\n",
    "        if override is None:\n",
    "            override=dict()\n",
    "        checkpoint=torch.load(os.path.join(prefix,name,'checkpoint.pth'))\n",
    "        self=cls(class_,**dict(**checkpoint['config'],**override))\n",
    "        self.inner.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optim.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.sched.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        self.total_iters=checkpoint['total_training_iters']\n",
    "        self.batch_size=checkpoint['last_batch_size']\n",
    "        self.train_loss_record=checkpoint['loss_record']['train']\n",
    "        self.test_loss_record=checkpoint['loss_record']['test']\n",
    "        self.best_eval_loss=min(self.test_loss_record.values())\n",
    "        self.training=training\n",
    "        return self\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa6ed525-9995-4232-9d4a-7a99a6a6e8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "split=RandomLinkSplit(num_val=0.1, num_test=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d412b5ed-8259-469e-89f1-49a4776d94df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl=DataLoader(ds,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82b0da28-126a-4e13-a003-81fc2b6c6ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DataBatch(x=[7431, 3], edge_index=[2, 254783], y=[7431], batch=[7431], ptr=[65], edge_label=[509566], edge_label_index=[2, 509566]),\n",
       " DataBatch(x=[7431, 3], edge_index=[2, 254783], y=[7431], batch=[7431], ptr=[65], edge_label=[72794], edge_label_index=[2, 72794]),\n",
       " DataBatch(x=[7431, 3], edge_index=[2, 291180], y=[7431], batch=[7431], ptr=[65], edge_label=[145588], edge_label_index=[2, 145588]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in dl:\n",
    "    break\n",
    "split(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec2ce35c-e969-4056-8e28-30c4b6fa9c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[34, 34], edge_index=[2, 156], y=[34], train_mask=[34]), 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GNNBenchmarkDataset()[0], len(GNNBenchmarkDataset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cac44aa3-b1ed-422a-90f3-f71cb8f5e09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[108, 3], edge_index=[2, 4884], y=[108]), 10000)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GNNBenchmarkDataset(\"datasets/gnnb-pattern\",name='PATTERN')[0], len(GNNBenchmarkDataset(\"datasets/gnnb-pattern\",name='PATTERN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de43b803-8d9e-4ee9-a008-c2054544d3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 020, Loss: 1.0626, Val AUC: 0.7143, Test AUC: 0.6489\n",
      "Epoch: 040, Loss: 0.9026, Val AUC: 0.6327, Test AUC: 0.7022\n",
      "Epoch: 060, Loss: 0.8517, Val AUC: 0.5714, Test AUC: 0.6444\n",
      "Epoch: 080, Loss: 0.8154, Val AUC: 0.5306, Test AUC: 0.6489\n",
      "Epoch: 100, Loss: 0.8225, Val AUC: 0.4898, Test AUC: 0.6133\n",
      "Epoch: 120, Loss: 0.7430, Val AUC: 0.4898, Test AUC: 0.6444\n",
      "Epoch: 140, Loss: 0.8061, Val AUC: 0.4286, Test AUC: 0.6444\n",
      "Epoch: 160, Loss: 0.8152, Val AUC: 0.4490, Test AUC: 0.6311\n",
      "Epoch: 180, Loss: 0.7157, Val AUC: 0.4898, Test AUC: 0.6222\n",
      "Epoch: 200, Loss: 0.8182, Val AUC: 0.3469, Test AUC: 0.5867\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import KarateClub\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Load the KarateClub dataset\n",
    "dataset = KarateClub()\n",
    "data = dataset[0]\n",
    "\n",
    "# If no node features are provided, use an identity matrix as one-hot encoding per node.\n",
    "if data.x is None:\n",
    "    data.x = torch.eye(data.num_nodes)\n",
    "\n",
    "# Use RandomLinkSplit to create training, validation, and test splits.\n",
    "# Note: is_undirected=True is set for an undirected graph.\n",
    "transform = RandomLinkSplit(num_val=0.1, num_test=0.2, is_undirected=True)\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "class GCNLinkPredictor(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCNLinkPredictor, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "    def decode(self, z, edge_index):\n",
    "        # Dot product decoder to compute the edge score.\n",
    "        return (z[edge_index[0]] * z[edge_index[1]]).sum(dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCNLinkPredictor(in_channels=train_data.x.size(1), hidden_channels=16, out_channels=16).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "train_data = train_data.to(device)\n",
    "val_data = val_data.to(device)\n",
    "test_data = test_data.to(device)\n",
    "\n",
    "def train(model, opetimizer, data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Encode nodes using only the training graph (with positive edges).\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    \n",
    "    # Compute positive edge scores using training edges.\n",
    "    pos_edge = data.edge_index\n",
    "    pos_scores = model.decode(z, pos_edge)\n",
    "    \n",
    "    # Negative sampling on the training graph.\n",
    "    neg_edge = negative_sampling(\n",
    "        edge_index=pos_edge,\n",
    "        num_nodes=data.num_nodes,\n",
    "        num_neg_samples=pos_edge.size(1)\n",
    "    )\n",
    "    neg_scores = model.decode(z, neg_edge)\n",
    "    \n",
    "    # Binary cross entropy loss.\n",
    "    pos_loss = -torch.log(torch.sigmoid(pos_scores) + 1e-15).mean()\n",
    "    neg_loss = -torch.log(1 - torch.sigmoid(neg_scores) + 1e-15).mean()\n",
    "    loss = pos_loss + neg_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, train_data, val_data, test_data):\n",
    "    model.eval()\n",
    "    # Use the training graph to compute node embeddings.\n",
    "    z = model.encode(train_data.x, train_data.edge_index).to(device)\n",
    "    \n",
    "    def compute_auc(split):\n",
    "        # Evaluate using the provided edge_label_index and edge_label.\n",
    "        scores = model.decode(z, split.edge_label_index)\n",
    "        scores = scores.cpu()\n",
    "        labels = split.edge_label.cpu()\n",
    "        return roc_auc_score(labels, scores)\n",
    "    \n",
    "    auc_val = compute_auc(val_data)\n",
    "    auc_test = compute_auc(test_data)\n",
    "    return auc_val, auc_test\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(1, 201):\n",
    "    loss = train(model, optimizer, train_data)\n",
    "    if epoch % 20 == 0:\n",
    "        auc_val, auc_test = test(model, train_data, val_data, test_data)\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val AUC: {auc_val:.4f}, Test AUC: {auc_test:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1674405-1640-4f95-9052-c2be9751942d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[34, 34], edge_index=[2, 156], y=[34], train_mask=[34])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KarateClub()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e0a20ac-0ca9-4e4d-aedc-7fb56aa8d2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_data.x).argwhere()[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cc3af9f-bcab-4217-80e3-3b22869b52a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "613d7e48-c5ce-4c78-890a-76432bb9f947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs in the dataset: 100\n",
      "Example graph: Data(x=[108, 3], edge_index=[2, 4884], y=[108])\n",
      "Epoch: 020, Loss: 1.2436, Val AUC: 0.5012, Test AUC: 0.5017\n",
      "Epoch: 040, Loss: 1.1926, Val AUC: 0.5012, Test AUC: 0.5018\n",
      "Epoch: 060, Loss: 1.1647, Val AUC: 0.5014, Test AUC: 0.5018\n",
      "Epoch: 080, Loss: 1.1799, Val AUC: 0.5016, Test AUC: 0.5018\n",
      "Epoch: 100, Loss: 1.1447, Val AUC: 0.5016, Test AUC: 0.5019\n",
      "Epoch: 120, Loss: 1.1428, Val AUC: 0.5016, Test AUC: 0.5019\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 99\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Main training loop.\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m201\u001b[39m):\n\u001b[1;32m---> 99\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    101\u001b[0m         auc_val \u001b[38;5;241m=\u001b[39m evaluate(val_loader)\n",
      "Cell \u001b[1;32mIn[15], line 66\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     64\u001b[0m pos_scores \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdecode(z, pos_edge)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# For negative sampling, sample as many negative edges as there are positive edges.\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m neg_edge \u001b[38;5;241m=\u001b[39m \u001b[43mnegative_sampling\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_edge\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_neg_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_edge\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m neg_scores \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdecode(z, neg_edge)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Compute binary cross entropy loss.\u001b[39;00m\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch_geometric\\utils\\_negative_sampling.py:102\u001b[0m, in \u001b[0;36mnegative_sampling\u001b[1;34m(edge_index, num_nodes, num_neg_samples, method, force_undirected)\u001b[0m\n\u001b[0;32m    100\u001b[0m idx \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):  \u001b[38;5;66;03m# Number of tries to sample negative indices.\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m     rnd \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m     mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misin(rnd\u001b[38;5;241m.\u001b[39mnumpy(), idx\u001b[38;5;241m.\u001b[39mnumpy())  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m neg_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch_geometric\\utils\\_negative_sampling.py:314\u001b[0m, in \u001b[0;36msample\u001b[1;34m(population, k, device)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39marange(population, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\random.py:502\u001b[0m, in \u001b[0;36mRandom.sample\u001b[1;34m(self, population, k, counts)\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m selected:\n\u001b[0;32m    501\u001b[0m             j \u001b[38;5;241m=\u001b[39m randbelow(n)\n\u001b[1;32m--> 502\u001b[0m         \u001b[43mselected_add\u001b[49m\u001b[43m(\u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m         result[i] \u001b[38;5;241m=\u001b[39m population[j]\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24a54042-a622-452b-a74a-e20e1dfcc2b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mbatch\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b5bdc7-c5a7-4084-90e2-e9f64aa0a739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
