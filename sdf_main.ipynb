{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0ba177b-d098-4bd4-9047-11ba249131f6",
   "metadata": {},
   "source": [
    "# Main thing\n",
    "\n",
    "We propose XGCN, an extension of RGCN to accomodate continuous features (with gpu-friendly operation)\n",
    "\n",
    "E: (N,N,R)\n",
    "\n",
    "A: (N,N)\n",
    "\n",
    "X: (N,H)\n",
    "\n",
    "stripped down formulation without MLPs (Don't know how to combine einsum notation with activation functions)\n",
    "\n",
    "$H_{ij}=E_{ikl}A_{ik}X_{kn}\\Theta_{lnj}$\n",
    "\n",
    "code:\n",
    "```python\n",
    "class XGCNConv(nn.Module):\n",
    "    def __init__(self, mlp_dims_edge, mlp_dims_node):\n",
    "        super().__init__()\n",
    "        self.mlp_dims_edge=mlp_dims_edge\n",
    "        self.mlp_dims_node=mlp_dims_node\n",
    "        self.mlp_edge = MLP(mlp_dims_edge[0], mlp_dims_edge[1:-1], mlp_dims_edge[-1])\n",
    "        self.mlp_node = MLP(mlp_dims_node[0], mlp_dims_node[1:-1], mlp_dims_node[-1])\n",
    "    def forward(self, x):\n",
    "        E, X, A, alt = x\n",
    "        tmp0=(self.mlp_edge(E)*A).permute(-1,0,1)\n",
    "        tmp1=tmp0@X\n",
    "        X = self.mlp_node(tmp1).permute(1,-1,0).sum(-1)\n",
    "        return E, X, A, alt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee7c8e25-4646-4aa2-8d18-4d5941b6236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from convertmol import parse_sdf_file, bond_type_dict, single_bond_stereo_dict, double_bond_stereo_dict\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import *\n",
    "from torch_geometric.utils import to_dense_adj, to_dense_batch, add_self_loops\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "import torch\n",
    "from torch import nn\n",
    "import rdkit\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from rdkit import Chem\n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import RDLogger\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# Suppress RDKit warnings\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "import sascorer\n",
    "torch.set_default_device('cpu:0')#'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf82fed2-41e7-4c8c-92bd-9fb8b94f3b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlp import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4500b96c-31b9-430f-b716-e6889aadacbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATOMS = {\n",
    "    'C':0,#6,\n",
    "    'N':1,#7,\n",
    "    'O':2,#8,\n",
    "    'F':3,#9,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a033c40-4f92-4796-b6fd-6f8462fce7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ATOMS=len(ATOMS)\n",
    "N_VALENCY=16 #ℤ∈[0,15]\n",
    "POS_DIM=3\n",
    "N_BOND_TYPES=len(bond_type_dict)\n",
    "N_BOND_STEREO_TYPES=max(len(single_bond_stereo_dict),len(double_bond_stereo_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b4392c4-dc81-475c-b9b4-d03138feb46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_valency(s):\n",
    "    if s == 'no marking':\n",
    "        return 15\n",
    "    if s == 'zero valence':\n",
    "        return 0\n",
    "    return int(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed5bab9b-64ff-474a-ac51-4568e6d216d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mapping(tensor, mapping):\n",
    "    # Convert the mapping dict to a tensor for efficient indexing\n",
    "    keys = torch.tensor(list(mapping.keys()))\n",
    "    values = torch.tensor(list(mapping.values()))\n",
    "\n",
    "    # Create a copy of the input tensor to avoid modifying it directly\n",
    "    result = tensor.clone()\n",
    "\n",
    "    # Create a mask to identify the indices that need to be replaced\n",
    "    for key, value in mapping.items():\n",
    "        # Apply the mapping\n",
    "        result[tensor == key] = value\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b163a2c1-d5c3-4bd1-95bf-5b3e5d2a848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_mol_dict(mol_dict:dict[str,str|dict[str,str|float]]):\n",
    "    'mol_dict is a part of the output of parse_sdf_file'\n",
    "    atoms=dict()\n",
    "    bonds=list()\n",
    "    for k,v in mol_dict.items():\n",
    "        if k.startswith(\"?atom\"):\n",
    "            atom_id = int(k[len(\"?atom\"):])\n",
    "            atoms[atom_id]=v\n",
    "        if (k.startswith(\"(\") and k.endswith(\")\")):\n",
    "            assert (v==True), \"don't know what non-True value means, here...\"\n",
    "            things = k[1:-1].split(\" \")\n",
    "            assert things[-1].startswith(\"?atom\"), \"invalid format\"\n",
    "            assert things[-2].startswith(\"?atom\"), \"invalid format\"\n",
    "            bond_type = list(bond_type_dict.values()).index(things[1])\n",
    "            if things[1]==\"Single\":\n",
    "                bond_stereo = list(single_bond_stereo_dict.values()).index(things[2])\n",
    "            elif things[1]==\"Double\":\n",
    "                bond_stereo = list(double_bond_stereo_dict.values()).index(things[2])\n",
    "            atom1_id = int(things[-2][len(\"?atom\"):])\n",
    "            #atom1_x = atoms[atom1_id]['x']\n",
    "            #atom1_y = atoms[atom1_id]['y']\n",
    "            #atom1_z = atoms[atom1_id]['z']\n",
    "            atom2_id = int(things[-1][len(\"?atom\"):])\n",
    "            #atom2_x = atoms[atom2_id]['x']\n",
    "            #atom2_y = atoms[atom2_id]['y']\n",
    "            #atom2_z = atoms[atom2_id]['z']\n",
    "            #l2_dist = ((atom1_x-atom2_x)**2+(atom1_y-atom2_y)**2+(atom1_z-atom2_z)**2)\n",
    "            if atoms[atom1_id]['symbol']=='H':\n",
    "                continue\n",
    "            if atoms[atom2_id]['symbol']=='H':\n",
    "                continue\n",
    "            bonds.append([bond_type, bond_stereo, atom1_id, atom2_id])\n",
    "    reindex={}\n",
    "    for k,v in atoms.items():\n",
    "        if v['symbol']!='H':\n",
    "            reindex[k]=len(reindex)\n",
    "    x=torch.tensor([\n",
    "        [ATOMS[atoms[k]['symbol']], convert_valency(atoms[k]['valence'])]\n",
    "        for k in reindex\n",
    "    ])\n",
    "    pos=torch.tensor([\n",
    "        [atoms[k]['x'], atoms[k]['y'], atoms[k]['z']]\n",
    "        for k in reindex\n",
    "    ])\n",
    "    bonds=torch.tensor(bonds)\n",
    "    edge_index=bonds[...,-2:].clone()\n",
    "    edge_index=apply_mapping(edge_index,reindex)\n",
    "    edge_attr=bonds[...,:-2].clone()\n",
    "    return Data(x=x,pos=pos,edge_index=edge_index.transpose(-2,-1),edge_attr=edge_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6456a8-a958-48e0-8e09-322135814a1f",
   "metadata": {},
   "source": [
    "# Extended Graph \n",
    "\n",
    "# Graph Convolutional Network (GCN)\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_i^{(k)} = \\sigma\\left(\\sum_{j \\in \\mathcal{N}(i)} \\frac{1}{\\sqrt{\\hat{d}_i \\hat{d}_j}} \\mathbf{W}^{(k)} \\mathbf{h}_j^{(k-1)} \\right)\n",
    "$$\n",
    "\n",
    "Where $(\\hat{d}_i)$ and $(\\hat{d}_j)$ are the degrees of nodes $(i)$ and $(j)$, including self-loops. $(\\sigma)$ is an activation function.\n",
    "\n",
    "# Relational Graph Convolutional Network (R-GCN)\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_i^{(k)} = \\sigma\\left(\\sum_{r \\in \\mathcal{R}} \\sum_{j \\in \\mathcal{N}r(i)} \\frac{1}{c_{i,r}} \\mathbf{W}_r^{(k)} \\mathbf{h}_j^{(k-1)}\\right)\n",
    "$$\n",
    "\n",
    "Designed for multi-relational graphs, using different weights $( \\mathbf{W}_r )$ for each edge type $( r )$.\n",
    "\n",
    "# GraphSAGE\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_i^{(k)} = \\sigma\\left(\\mathbf{W}^{(k)} \\cdot \\text{AGGREGATE}\\left({\\mathbf{h}_j^{(k-1)}, \\forall j \\in \\mathcal{N}(i)}\\right)\\right)\n",
    "$$\n",
    "\n",
    "\"AGGREGATE\" can be operations like mean, LSTM, or pooling.\n",
    "\n",
    "# Graph Attention Network (GAT)\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_i^{(k)} = \\sigma\\left(\\sum_{j \\in \\mathcal{N}(i)} \\alpha_{ij}^{(k)} \\mathbf{W}^{(k)} \\mathbf{h}_j^{(k-1)} \\right)\n",
    "$$\n",
    "\n",
    "$(\\alpha_{ij}^{(k)})$ are attention coefficients computed as: \n",
    "\n",
    "$$\n",
    "\\alpha_{ij}^{(k)} = \\frac{\\exp\\left(\\text{LeakyReLU}\\left(\\mathbf{a}^{\\top}[\\mathbf{W}\\mathbf{h}_i^{(k-1)} |\\mathbf{W}\\mathbf{h}j^{(k-1)}]\\right)\\right)}{\\sum{k \\in \\mathcal{N}(i)} \\exp\\left(\\text{LeakyReLU}\\left(\\mathbf{a}^{\\top}[\\mathbf{W}\\mathbf{h}_i^{(k-1)} |\\mathbf{W}\\mathbf{h}_k^{(k-1)}]\\right)\\right)}\n",
    "$$\n",
    "\n",
    "Where $(| )$ denotes concatenation.\n",
    "\n",
    "# Graph Isomorphism Network (GIN)\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_i^{(k)} = \\text{MLP}^{(k)}\\left(\\left(1 + \\epsilon^{(k)}\\right) \\mathbf{h}_i^{(k-1)} + \\sum_{j \\in \\mathcal{N}(i)} \\mathbf{h}_j^{(k-1)}\\right)\n",
    "$$\n",
    "\n",
    "MLP is a multi-layer perceptron. $(\\epsilon^{(k)})$ is a learnable or fixed scalar.\n",
    "\n",
    "# Message Passing Neural Network (MPNN)\n",
    "\n",
    "$$\n",
    "\\mathbf{m}_{ij}^{(k)} = \\text{MESSAGE}(\\mathbf{h}_i^{(k-1)}, \\mathbf{h}_j^{(k-1)}, \\mathbf{e}_{ij})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_i^{(k)} = \\text{UPDATE}(\\mathbf{h}_i^{(k-1)}, \\sum_{j \\in \\mathcal{N}(i)} \\mathbf{m}_{ij}^{(k)})\n",
    "$$\n",
    "\n",
    "This formulation allows for $( \\mathbb{R}^d)$ features on both nodes and edges, making it versatile for handling various data types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098c2a00-1e96-4805-8695-b51c1666259c",
   "metadata": {},
   "source": [
    "$E: (|V|, |V|, He)$\n",
    "\n",
    "$A: (|V|, |V|)$\n",
    "\n",
    "$V: (|V|, Hv)$\n",
    "\n",
    "$X: (|V|, Hx)$\n",
    "\n",
    "$W: (He, Hv)$\n",
    "\n",
    "$U: (Hx, Hv)$\n",
    "\n",
    "$X = \\text{MLP}(\\text{MLP}(E)\\odot AXU)$\n",
    "\n",
    "$E = EW$\n",
    "\n",
    "___\n",
    "\n",
    "Where $L$ is an affine transformation\n",
    "\n",
    "$\\mathbf{E^{(t+1)}}=\\mathbf{E^{(t)}}.(L.\\sigma)*$\n",
    "\n",
    "$\\mathbf{X^{(t+1)}}=(\\mathbf{E^{(t+1)}}{\\circ}A)\\mathbf{X}.(L.\\sigma)*$\n",
    "\n",
    "---\n",
    "\n",
    "We define XGCN as the following atomic operation performed in order\n",
    "\n",
    "$\\mathbf{E}:=\\mathbf{E}.(L.\\sigma)*$\n",
    "\n",
    "$\\mathbf{X}:=(\\mathbf{E}{\\circ}\\mathbf{A})\\mathbf{X}.(L.\\sigma)*$\n",
    "\n",
    "---\n",
    "\n",
    "$\\mathbf{E}:=\\mathbf{E}\\triangleright(L\\triangleright\\sigma)*$\n",
    "\n",
    "$\\mathbf{X}:=(\\mathbf{E}{\\circ}\\mathbf{A})\\mathbf{X}\\triangleright(L\\triangleright\\sigma)*$\n",
    "\n",
    "\n",
    "$L\\mathit{L}\\mathcal{L}\\mathbb{L}\\mathrm{L}\\mathbf{L}\\mathcal{\\sigma}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b34b9b77-dc6b-4116-8579-687087bf5762",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InitialTransformation(nn.Module):\n",
    "    def __init__(self, atom_hdim, valency_hdim, bond_type_hdim, bond_stereo_type_hdim):\n",
    "        super().__init__()\n",
    "        self.atom_hdim = atom_hdim\n",
    "        self.valency_hdim = valency_hdim\n",
    "        self.bond_type_hdim = bond_type_hdim\n",
    "        self.bond_stereo_type_hdim = bond_stereo_type_hdim\n",
    "        self.emb1 = nn.Embedding(N_ATOMS, atom_hdim)\n",
    "        self.emb2 = nn.Embedding(N_VALENCY, valency_hdim)\n",
    "        self.emb3 = nn.Embedding(N_BOND_TYPES, bond_type_hdim)\n",
    "        self.emb4 = nn.Embedding(N_BOND_STEREO_TYPES, bond_stereo_type_hdim)\n",
    "    def forward(self, x: Data, use_alt=False):\n",
    "        if not x.is_undirected():\n",
    "            edge_index=torch.cat([x.edge_index,x.edge_index[...,[1,0],:]],-1)\n",
    "            edge_attr=torch.cat([x.edge_attr,x.edge_attr],-2)\n",
    "        else:\n",
    "            edge_index=edge_index\n",
    "            edge_attr=edge_attr\n",
    "        ### A\n",
    "        if not use_alt:\n",
    "            A = to_dense_adj(edge_index).permute(1,-1,0)\n",
    "\n",
    "        ### X\n",
    "        emb1 = self.emb1(x.x[...,0].to(torch.long))\n",
    "        emb2 = self.emb2(x.x[...,1].to(torch.long))\n",
    "        X = torch.cat([emb1, emb2],-1)\n",
    "        \n",
    "        emb3 = self.emb3(edge_attr[...,0])\n",
    "        emb4 = self.emb4(edge_attr[...,1])\n",
    "        orig,dest=x.pos[edge_index]\n",
    "        diff=dest-orig\n",
    "        dist=torch.linalg.norm(diff,ord=2,dim=-1).view(-1,1)\n",
    "        __n = x.x.shape[0]\n",
    "        E = torch.zeros(__n, __n, self.bond_type_hdim+self.bond_stereo_type_hdim+POS_DIM+1)\n",
    "        E[edge_index[0], edge_index[1]] = torch.cat([\n",
    "            emb3,\n",
    "            emb4,\n",
    "            diff,\n",
    "            dist\n",
    "        ],-1)\n",
    "        if use_alt:\n",
    "            return X, edge_index, torch.cat([\n",
    "                    emb3,\n",
    "                    emb4,\n",
    "                    diff,\n",
    "                    dist\n",
    "                ],-1)\n",
    "        return E,X,A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ccc5a2-4c35-46e9-aab1-6bd0eb5c5ffc",
   "metadata": {},
   "source": [
    "When dealing with permutations of tensors in mathematical or scientific papers, several notations and symbols are typically used to convey the operations clearly. Here are some common notations and symbols you might consider using:\n",
    "\n",
    "Indices and Einstein Notation:\n",
    "\n",
    "Using indices, especially in Einstein summation notation, can help describe permutations or operations on tensors. For instance, if you have a tensor $T_{ijk}$, a permutation of its indices might result in $T_{jik}$, which expresses swapping the first and second indices.\n",
    "Permutation Symbol $(\\pi)$:\n",
    "\n",
    "A permutation can be denoted by a specific symbol, such as $\\pi$, representing a permutation of indices. For example, $\\pi = (2 , 3 , 1)$ could denote the permutation that maps the first index to the third, the second to the first, and the third to the second.\n",
    "Levi-Civita Symbol $(\\varepsilon_{ijk\\ldots})$:\n",
    "\n",
    "The Levi-Civita symbol is often used to express permutations, particularly in three dimensions. It can describe the sign of a permutation or indicate cross products in vector calculus.\n",
    "Cycle Notation:\n",
    "\n",
    "Cycles are a typical way of expressing permutations. For example, the permutation $(1, 2, 3)$ denotes a cyclic shift where the first element moves to the position of the second, the second to the third, and the third to the first.\n",
    "Pi $(\\Pi)$ and Sigma $(\\Sigma)$ Notation:\n",
    "\n",
    "Sometimes, authors use uppercase Greek letters like $\\Pi$ or $\\Sigma$ to represent specific permutations or permutation matrices. These can be accompanied by subscripts to indicate particular permutations, such as $\\Pi_{\\sigma}$.\n",
    "Kronecker Delta $(\\delta_{ij})$:\n",
    "\n",
    "Used in conjunction with permutations for summing over indices or in expressions involving tensors and ensuring certain terms only appear when indices match.\n",
    "When authoring your paper, choose the notation that best fits the conventions of your field or the style of your paper. It’s crucial to define any notation clearly when it first appears to ensure that readers understand how you are using it. Providing illustrative examples or diagrams can further aid comprehension, particularly for more complicated tensor operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cecbfa-a34e-47ed-a629-55d67fb15d40",
   "metadata": {},
   "source": [
    "We define XGCN as the following atomic operation performed in order\n",
    "\n",
    "$\\mathbf{E}:=\\mathbf{E}.(L.\\sigma)*$\n",
    "\n",
    "$\\mathbf{X}:=(\\mathbf{E}{\\circ}\\mathbf{A})\\mathbf{X}.(L.\\sigma)*$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96787913-95c8-4462-8d4b-ba63c4b9a5c8",
   "metadata": {},
   "source": [
    "We define XGCN as the following operation\n",
    "\n",
    "$\\mathbf{X_ij}:=\\mathbf{E}.(L.\\sigma)^*{\\circ}\\mathbf{A_nn}\\mathbf{X_no}.(L.\\sigma)^*.\\Sigma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26ad8065-3c71-4742-b8e2-16ff791b76f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGCNConv(nn.Module):\n",
    "    def __init__(self, mlp_dims_edge, mlp_dims_node, dropout_rate=0.0):\n",
    "        super().__init__()\n",
    "        self.mlp_edge = MLP(mlp_dims_edge[0], mlp_dims_edge[1:-1], mlp_dims_edge[-1], dropout_rate=dropout_rate)\n",
    "        self.mlp_node = MLP(mlp_dims_node[0], mlp_dims_node[1:-1], mlp_dims_node[-1], dropout_rate=dropout_rate)\n",
    "    def forward(self, x):\n",
    "        E, X, A = x\n",
    "        __E=self.mlp_edge(E)\n",
    "        __EAX=(torch.einsum('bca,bc,ce->bae',__E, A[...,0], X))\n",
    "        __X = self.mlp_node(__EAX).sum(-2)\n",
    "        return E, __X, A\n",
    "\n",
    "\n",
    "#if not alt:\n",
    "#    __EA = (__E*A).permute(-1,0,1)\n",
    "#    __EAX = __EA@X\n",
    "#    __X = self.mlp_node(__EAX).permute(1,-1,0).sum(-1)\n",
    "#else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7faf96b0-7cc2-4f51-8406-31211837e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GINEConv(MessagePassing):\n",
    "    def __init__(self, mlp_dims_edge, mlp_dims_node, eps=0, train_eps=False, dropout_rate=0.0):\n",
    "        super().__init__(aggr='add')  # \"Add\" aggregation.\n",
    "        self.mlp = MLP(mlp_dims_node[0], mlp_dims_node[1:-1], mlp_dims_node[-1], dropout_rate=dropout_rate)  # Node feature MLP\n",
    "        self.edge_mlp = MLP(mlp_dims_edge[0], mlp_dims_edge[1:-1], mlp_dims_edge[-1], dropout_rate=dropout_rate)  # Edge feature MLP\n",
    "        self.eps = torch.nn.Parameter(torch.Tensor([eps])) if train_eps else eps\n",
    "\n",
    "    def forward(self, _x):\n",
    "        x, edge_index, edge_attr=_x\n",
    "        print(f\"x: {x.dtype}\")\n",
    "        print(f\"edge_index: {edge_index.dtype}\")\n",
    "        print(f\"edge_attr: {edge_attr.dtype}\")\n",
    "        # Add self-loops to the edge_index\n",
    "        #edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        # Pass edge_attr through edge MLP\n",
    "        print(f\"edge_attr: {edge_attr.shape}\")\n",
    "        print(\"self.edge_mlp()\")\n",
    "        edge_attr = self.edge_mlp(edge_attr)\n",
    "        print(\"self.propagate()\")\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        # Aggregate messages with edge features\n",
    "        print(\"message()\")\n",
    "        return x_j + edge_attr\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        print(\"update()\")\n",
    "        return self.mlp((1 + self.eps) * x + aggr_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af9ce4f1-aae8-438d-8e03-7ab3d6c9aaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGCNWithTransformation(nn.Module):\n",
    "    def __init__(self, atom_hdim, valency_hdim, bond_type_hdim, bond_stereo_type_hdim, mlp_dims_edge, mlp_dims_node,use_alt=False):\n",
    "        super().__init__()\n",
    "        mlp_dims_edge=deepcopy(mlp_dims_edge)\n",
    "        mlp_dims_node=deepcopy(mlp_dims_node)\n",
    "        for i in range(len(mlp_dims_edge)):\n",
    "            mlp_dims_edge[i]=[bond_type_hdim+bond_stereo_type_hdim+POS_DIM+1]+mlp_dims_edge[i]\n",
    "        mlp_dims_node[0]=[atom_hdim+valency_hdim]+mlp_dims_node[0]\n",
    "        self.use_alt=use_alt\n",
    "        self.xgcn=nn.Sequential(*[\n",
    "                GINEConv(de,dn) if use_alt else XGCNConv(de,dn)\n",
    "                for de, dn in (zip(mlp_dims_edge, mlp_dims_node))\n",
    "            ])\n",
    "        self.transform=InitialTransformation(atom_hdim, valency_hdim ,bond_type_hdim,bond_stereo_type_hdim)\n",
    "    def forward(self, x: Data):\n",
    "        return self.xgcn(self.transform(x,use_alt=self.use_alt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f54c78c3-2bee-4c1d-ac9b-b9e93cb810ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_type_hdim=3\n",
    "bond_stereo_type_hdim = 3\n",
    "atom_hdim=3\n",
    "valency_hdim=3\n",
    "mlp_dims_edge=[\n",
    "    [32,16],\n",
    "    #[16,32],\n",
    "]\n",
    "mlp_dims_node=[\n",
    "    [10,32],\n",
    "    #[32,10],\n",
    "]\n",
    "model =   XGCNWithTransformation(atom_hdim, valency_hdim , bond_type_hdim, bond_stereo_type_hdim, mlp_dims_edge, mlp_dims_node, use_alt=False)\n",
    "model_alt=XGCNWithTransformation(atom_hdim, valency_hdim , bond_type_hdim, bond_stereo_type_hdim, mlp_dims_edge, mlp_dims_node, use_alt=True)\n",
    "for m,m_alt in zip(model.xgcn,model_alt.xgcn):\n",
    "    m_alt.edge_mlp = m.mlp_edge\n",
    "    m_alt.mlp = m.mlp_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c576ce7-4c37-4fba-98f7-2408109a4887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[8, 2], edge_index=[2, 7], edge_attr=[7, 2], pos=[8, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=parse_mol_dict(parse_sdf_file(\"example.mol\")[0])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c24d89e9-ef1c-4f5e-a8b2-c5efd92fe15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "E, H, A=model.xgcn(model.transform(d,use_alt=model.use_alt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e9bcebdf-c018-47e7-847e-f121d2941a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.float32\n",
      "edge_index: torch.int64\n",
      "edge_attr: torch.float32\n",
      "edge_attr: torch.Size([14, 10])\n",
      "self.edge_mlp()\n",
      "self.propagate()\n",
      "message()\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (6) must match the size of tensor b (16) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m E, H, A\u001b[38;5;241m=\u001b[39m\u001b[43mmodel_alt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxgcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_alt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43muse_alt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_alt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_alt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[70], line 20\u001b[0m, in \u001b[0;36mGINEConv.forward\u001b[1;34m(self, _x)\u001b[0m\n\u001b[0;32m     18\u001b[0m edge_attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_mlp(edge_attr)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself.propagate()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:547\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[1;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    546\u001b[0m         msg_kwargs \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[1;32m--> 547\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessage(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmsg_kwargs)\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m    549\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (msg_kwargs, ), out)\n",
      "Cell \u001b[1;32mIn[70], line 25\u001b[0m, in \u001b[0;36mGINEConv.message\u001b[1;34m(self, x_j, edge_attr)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmessage\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_j, edge_attr):\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# Aggregate messages with edge features\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx_j\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\utils\\_device.py:77\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[1;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (6) must match the size of tensor b (16) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "E, H, A=model_alt.xgcn(model_alt.transform(d,use_alt=model_alt.use_alt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "42562c3b-ea25-4885-9f73-630849463c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 1., 0.],\n",
       "        [0., 0., 1., 0., 1., 0., 0., 1.],\n",
       "        [0., 0., 0., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transform(d,use_alt=model.use_alt)[-1].squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "05cb9759-0c9a-46d0-b677-58e6923cd6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transform(d,use_alt=model_alt.use_alt)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "b74b32a5-c0ed-4b21-b3ba-1db084c54d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_attr = tensor([[0, 0],\n",
      "        [1, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [1, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0],\n",
      "        [0, 0]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Long and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[333], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m out2\u001b[38;5;241m=\u001b[39m\u001b[43mmodel_alt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxgcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43muse_alt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_alt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_alt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[328], line 14\u001b[0m, in \u001b[0;36mGINEConv.forward\u001b[1;34m(self, _x)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Add self-loops to the edge_index\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Pass edge_attr through edge MLP\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00medge_attr\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m= }\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m edge_attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_mlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39mx, edge_attr\u001b[38;5;241m=\u001b[39medge_attr)\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\drugs\\mlp.py:29\u001b[0m, in \u001b[0;36mMLP.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\micromamba\\envs\\drugresearch\\lib\\site-packages\\torch\\utils\\_device.py:77\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[1;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Long and Float"
     ]
    }
   ],
   "source": [
    "out2=model_alt.xgcn(model.transform(d,use_alt=model_alt.use_alt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "e14cf652-39b4-4393-b118-df3d0f95bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "e,h,a,alt=model(d,alt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "4725c082-054b-4f3c-a06e-441321b7f145",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, h2, _, _=model(d, alt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "53e52613-88f5-4a93-b9b4-96145207bb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 7])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "760191ed-0160-4620-8395-65f3b6e1ef6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 8, 6]),\n",
       " torch.Size([10, 8, 6]),\n",
       " tensor(0., grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0=((e*a).permute(-1,0,1)@x)\n",
    "t2=torch.einsum('bca,bc,ce->bae',e, a[...,0], x).transpose(0,1)\n",
    "t2.shape,t0.shape,(t2-t0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "350454a3-f277-43de-bb1d-2f1dc6e64763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([111, 8, 6]),\n",
       " torch.Size([8, 111, 6]),\n",
       " tensor(0., grad_fn=<SumBackward0>))"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape,h2.shape,(h.transpose(0,1)-h2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "331a6b64-44a8-4556-9a72-ba70e7cd98e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((torch.einsum('bca,bc->bca',__E, A[...,0])-(__E*A))**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "77965e17-1786-4673-8fa8-85cb4bc4a6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5983, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x.transpose(0,1)-x2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4a080454-f7c6-4fed-b84c-8b54fb39506c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([111, 8, 6])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1=torch.einsum('bca,bc,ce->abe',__E, A[...,0], X)\n",
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3dfdbe5d-b638-4b8b-bbda-98fe2e6b1732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((t1-t0)**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1277135c-478e-4831-8a2c-38519de9feab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((t2-t0)**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3161c73e-328d-41d4-8c18-c4d6d27af49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(e-e2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4a434a76-748c-4c10-9706-cea12090419b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4257, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x-x2.transpose(0,1)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "549b8719-3871-46a2-ba34-57c3e2c95656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 111, 6])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0f9e4832-1088-45c3-bd3f-41e5efd1600a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3] [3, 4] [1, 2] [2, 3, 4]\n",
      "[3, 4] [4, 5, 6] [2, 3, 4] [4, 10, 1]\n"
     ]
    }
   ],
   "source": [
    "a=[\n",
    "    [1,2,3],\n",
    "    [3,4],\n",
    "    [4,5,6]\n",
    "]\n",
    "b=[\n",
    "    [1,2],\n",
    "    [2,3,4],\n",
    "    [4,10,1]\n",
    "]\n",
    "for (a1,b1),(a2,b2) in itertools.pairwise(zip(a,b)):\n",
    "    print(a1,a2,b1,b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "df32443f-a6e1-4919-b0c6-daa0dd4301ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdb9=pd.read_csv(\"gdb9.sdf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "b4631847-a3cc-4fbd-b40d-4713bcd38af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gdb9['u0'].plot.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f11f6f63-6a4f-4993-9c6e-9f6570f4019c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 8, 8]), torch.Size([8, 5]), torch.Size([8, 8, 1]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.shape,x.shape,a.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9fe63566-53d9-4860-83ea-0b580e9e5a1c",
   "metadata": {},
   "source": [
    "Wr: (R, I, O)\n",
    "W0: (I, O)\n",
    "X: (N, I)\n",
    "A: (R, N, N)\n",
    "\n",
    "t1 := X.Wr |> (N,I)x(R,I,O) #(N, R, O)\n",
    "t2 := t1.transpose(-3,-2) #(R,N,O)\n",
    "t3 := A@t2 #(R,N,O)\n",
    "t4 := t3.sum(-3) #(N,O)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a697564d-5ab2-45d8-b2c3-680df3d840d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "__num_nodes=9\n",
    "__x_features=5\n",
    "__x_dims=3\n",
    "__e_features=2\n",
    "x=torch.randn(__num_nodes,__x_features)\n",
    "wr=torch.randn(__e_features,__x_features,__x_dims)\n",
    "e=torch.randn(__num_nodes,__num_nodes,__e_features)\n",
    "a=(torch.randn(__num_nodes,__num_nodes)>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "2f7d0d65-076c-4ee8-84a5-714120c76644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 3])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__x=torch.einsum(x, [..., 0, 1], wr, [2, 1, 3], [..., 2, 0, 3])\n",
    "__y=torch.einsum(e*a, [..., 1, 2, 0], __x, [..., 0,2,3], [1, 3])#.sum(-3)\n",
    "__y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "fc05e4e3-c14f-4bd9-a281-24790bdf6db1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000e+00,  0.0000e+00],\n",
       "         [ 1.0230e+00,  2.4992e+00],\n",
       "         [-0.0000e+00, -0.0000e+00],\n",
       "         [-1.3810e+00, -5.6486e-01],\n",
       "         [ 1.7939e-01,  1.0669e+00],\n",
       "         [-0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00],\n",
       "         [-0.0000e+00,  0.0000e+00],\n",
       "         [-4.3401e-01,  1.2213e+00]],\n",
       "\n",
       "        [[ 1.2168e+00,  5.2161e-01],\n",
       "         [ 3.1140e-01,  1.8250e+00],\n",
       "         [-0.0000e+00,  0.0000e+00],\n",
       "         [-1.1819e+00,  1.8025e+00],\n",
       "         [-1.4961e-01,  4.3280e-03],\n",
       "         [-0.0000e+00, -0.0000e+00],\n",
       "         [-9.3037e-01,  2.2996e+00],\n",
       "         [-9.9957e-01, -2.3330e+00],\n",
       "         [-0.0000e+00, -0.0000e+00]],\n",
       "\n",
       "        [[-0.0000e+00,  0.0000e+00],\n",
       "         [-1.5654e+00, -2.7474e-01],\n",
       "         [ 1.0368e-03, -6.9726e-01],\n",
       "         [ 4.3336e-01, -1.2369e+00],\n",
       "         [ 1.3748e+00,  1.0889e+00],\n",
       "         [-3.8909e-01, -2.4145e-01],\n",
       "         [ 0.0000e+00, -0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00],\n",
       "         [-0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-0.0000e+00, -0.0000e+00],\n",
       "         [-4.9453e-01,  8.6590e-02],\n",
       "         [-3.1632e-01,  1.1465e-01],\n",
       "         [-6.3096e-01,  2.6044e-01],\n",
       "         [ 0.0000e+00, -0.0000e+00],\n",
       "         [ 4.6839e-01,  6.6120e-02],\n",
       "         [-2.9430e-01, -4.2721e-01],\n",
       "         [ 2.1182e-01, -6.1292e-01],\n",
       "         [-1.7340e-01,  6.3851e-01]],\n",
       "\n",
       "        [[ 2.2925e+00,  2.0758e-01],\n",
       "         [ 4.3587e-01, -2.0736e+00],\n",
       "         [-1.3318e+00, -1.6193e+00],\n",
       "         [-8.8936e-01, -9.6646e-01],\n",
       "         [-0.0000e+00, -0.0000e+00],\n",
       "         [-2.2970e+00, -1.6719e-01],\n",
       "         [-6.9995e-02, -2.1586e+00],\n",
       "         [ 8.3149e-02,  1.2058e-01],\n",
       "         [-3.3190e+00,  7.3078e-01]],\n",
       "\n",
       "        [[ 0.0000e+00, -0.0000e+00],\n",
       "         [ 0.0000e+00, -0.0000e+00],\n",
       "         [-0.0000e+00, -0.0000e+00],\n",
       "         [-6.3864e-02, -3.9233e-01],\n",
       "         [ 1.3728e-01,  9.2219e-01],\n",
       "         [-8.2082e-01,  5.7503e-01],\n",
       "         [-3.1678e+00, -1.9338e-02],\n",
       "         [ 0.0000e+00, -0.0000e+00],\n",
       "         [ 2.7469e-01, -5.3956e-01]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00],\n",
       "         [ 8.2574e-01, -9.0141e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00, -0.0000e+00],\n",
       "         [-0.0000e+00, -0.0000e+00],\n",
       "         [-0.0000e+00,  0.0000e+00],\n",
       "         [-0.0000e+00, -0.0000e+00],\n",
       "         [-0.0000e+00, -0.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00, -0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00],\n",
       "         [-0.0000e+00, -0.0000e+00],\n",
       "         [-0.0000e+00, -0.0000e+00],\n",
       "         [ 6.6092e-01,  1.3461e+00],\n",
       "         [-6.2042e-01, -6.7347e-02],\n",
       "         [ 8.9868e-01, -6.2987e-01],\n",
       "         [-0.0000e+00,  0.0000e+00],\n",
       "         [-0.0000e+00, -0.0000e+00]],\n",
       "\n",
       "        [[-4.7107e-01, -7.2189e-02],\n",
       "         [-0.0000e+00, -0.0000e+00],\n",
       "         [ 5.4541e-01,  2.0277e-01],\n",
       "         [-0.0000e+00, -0.0000e+00],\n",
       "         [ 5.2471e-01, -2.0891e+00],\n",
       "         [ 2.7036e+00,  6.6574e-01],\n",
       "         [ 1.2451e-01,  1.0114e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00],\n",
       "         [-0.0000e+00, -0.0000e+00]]])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('abc,ab->abc',e,a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f3806f-a146-472b-a8be-94ad27ac63c0",
   "metadata": {},
   "source": [
    "$O_{kil}=X_{ij}W_{kjl}$\n",
    "\n",
    "$H_{bd}=E_{abc}O_{acd}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5806b8b9-bec1-4b2a-82de-aacf05a13acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 3])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__t=torch.einsum('bca,bcf,ce,aed->bd',e,a,x,wr)\n",
    "__t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "9b9b599e-027e-4967-b497-af00436c1913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 2, 5])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('bca,bc,ce->bae',e,a,x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "f7fc99f4-edf3-4585-86c4-4b219483a0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__t=torch.einsum('bca,bc,ce,aed->bd',e,a,x,wr)\n",
    "__t1=(torch.einsum('bca,bc,ce->bae',e,a,x))\n",
    "__t2=torch.einsum('bae,aed->bd',__t1,wr)\n",
    "(__t2-__t).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "2a04388f-2ca6-4529-afe2-158f5904485f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9, 2, 5]), torch.Size([9, 3]), torch.Size([9, 3]))"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__t1.shape,__t2.shape,__t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "047dbf28-d200-4427-bc70-5f49a2471303",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.],\n",
       "         [0., 0.]]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(e*a)-torch.einsum('abc,ab->abc',e,a[...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "dc8dfe17-93d8-4303-a23e-7809d163c3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 3])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__t=torch.einsum('ikl,ik,kn,lnj->ij',e,a,x,wr)\n",
    "__t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "7b8bf08e-2b23-450a-ab8b-c401c1946a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -9.1913, -14.3609,   6.9741],\n",
       "        [-17.4646,   8.2747,  25.5398],\n",
       "        [  0.3774,  -1.2827,  -7.9322],\n",
       "        [ -7.4846,   3.7114,  -1.0713],\n",
       "        [ 43.9281, -15.0339,  -5.0697],\n",
       "        [ -2.6267,  -1.7418,  -6.1004],\n",
       "        [  2.5439,  -1.1132,  -4.7787],\n",
       "        [  1.8885,  -7.8162,   1.6850],\n",
       "        [-18.5795,   5.4802,  -1.8069]])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6619c713-6221-4435-be5b-62f8e0e92e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "self.num_relations=len(BONDS)-1\n",
    "self.in_dim=in_dim\n",
    "self.out_dim=out_dim\n",
    "self.do_rate=do_rate\n",
    "self.wr=nn.Parameter(torch.empty(self.num_relations, in_dim, out_dim))\n",
    "self.w0=nn.Parameter(torch.empty(in_dim, out_dim))\n",
    "def forward(self, \n",
    "            inputs, \n",
    "            use_old=False\n",
    "           ):\n",
    "    if use_old:\n",
    "        raise Exception(\"use_old is not allowed\")\n",
    "    X,A=inputs\n",
    "    right_side=X@self.w0\n",
    "\n",
    "    tmp1 = torch.einsum(X, [..., 0, 1], self.wr, [2, 1, 3], [..., 0, 2, 3]).transpose(-3,-2)\n",
    "    #we use A[...,1:,:,:] <- the 1: is important because A[...,0,:,:] is the ZERO BOND therefor they shouldn't propagate\n",
    "    tmp2 = (A[...,1:,:,:]@tmp1)\n",
    "    cir = (A[...,1:,:,:].sum(-1).unsqueeze(-1))\n",
    "    #print(cir.shape, tmp2.shape)\n",
    "    #raise Exception(\"Bruh\")\n",
    "    # Method 1 (error in back propagation)\n",
    "    #tmp2_div_cir = torch.where((tmp2 == 0) & (cir == 0), torch.tensor(0.0), tmp2 / cir)\n",
    "    \n",
    "    # Method 2 (bad feeling about this, because of epsilon)\n",
    "    #tmp2_div_cir = tmp2 / (cir+1e-9)\n",
    "    \n",
    "    # Method 3\n",
    "    tmp2_div_cir = tmp2*torch.where(cir==0.0, 0.0, 1/cir)\n",
    "    \n",
    "    \n",
    "    left_side = tmp2_div_cir.sum(-3)\n",
    "    h = left_side+right_side\n",
    "    if self.activation_function is not None:\n",
    "        h =self.activation_function(h)\n",
    "    h=nn.functional.dropout(h,p=self.do_rate)\n",
    "    return h,A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b278de-ef6b-432e-928c-86d6ac0425f0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "$$\n",
    "\\mathbf{m}_{ij}^{(k)} = \\text{MESSAGE}(\\mathbf{h}_i^{(k-1)}, \\mathbf{h}_j^{(k-1)}, \\mathbf{e}_{ij})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_i^{(k)} = \\text{UPDATE}(\\mathbf{h}_i^{(k-1)}, \\text{PROPAGATE}( \\mathbf{m}_{ij}^{(k)} | j \\in \\mathcal{N}(i)))\n",
    "$$\n",
    "\n",
    "\n",
    "# Ways of incorporating edge features\n",
    "\n",
    "## Addition\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_i^{(k)} = \\text{MLP}^{(k)}\\left(\\left(1 + \\epsilon^{(k)}\\right) \\mathbf{h}_i^{(k-1)} + \\sum_{j \\in \\mathcal{N}(i)} \\mathbf{h}_j^{(k-1)}\\right)\n",
    "$$\n",
    "\n",
    "## Ours\n",
    "\n",
    "$$\n",
    "E \\cdot A X W\n",
    "$$\n",
    "\n",
    "where the node-wise formulation is:\n",
    "\n",
    "$$\n",
    "h_i^{t+1}\n",
    "$$\n",
    "\n",
    "# Graph Isomorphism Network (GIN)\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_i^{(k)} = \\text{MLP}^{(k)}\\left(\\left(1 + \\epsilon^{(k)}\\right) \\mathbf{h}_i^{(k-1)} + \\sum_{j \\in \\mathcal{N}(i)} \\mathbf{h}_j^{(k-1)}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "# Graph Convolutional Network (GCN)\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_i^{(k)} = \\sigma\\left(\\sum_{j \\in \\mathcal{N}(i)} \\frac{1}{\\sqrt{\\hat{d}_i \\hat{d}_j}} \\mathbf{W}^{(k)} \\mathbf{h}_j^{(k-1)} \\right)\n",
    "$$\n",
    "\n",
    "Where $(\\hat{d}_i)$ and $(\\hat{d}_j)$ are the degrees of nodes $(i)$ and $(j)$, including self-loops. $(\\sigma)$ is an activation function.\n",
    "\n",
    "# Relational Graph Convolutional Network (R-GCN)\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_i^{(k)} = \\sigma\\left(\\sum_{r \\in \\mathcal{R}} \\sum_{j \\in \\mathcal{N}r(i)} \\frac{1}{c_{i,r}} \\mathbf{W}_r^{(k)} \\mathbf{h}_j^{(k-1)}\\right)\n",
    "$$\n",
    "\n",
    "Designed for multi-relational graphs, using different weights $( \\mathbf{W}_r )$ for each edge type $( r )$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0115ef-19b4-4f09-ab68-ff5218b85e29",
   "metadata": {},
   "source": [
    "# GCN\n",
    "\n",
    "$$\n",
    "X=\\hat{A}X.L.\\sigma\n",
    "$$\n",
    "\n",
    "# GIN\n",
    "\n",
    "$$\n",
    "h_i := \\{h_i\\} || \\mathcal{N}(h_i) . {\\textstyle \\sum} .  ( L . \\sigma ) *\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{X}:=\\mathbf{\\hat{A}}\\mathbf{X}.(L.\\sigma)*\n",
    "$$\n",
    "\n",
    "# 3 layer MLP\n",
    "\n",
    "$$\n",
    "X .  ( L . \\sigma ) *\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85b126c-f954-42c8-bfbc-47e8eb0ffb75",
   "metadata": {},
   "source": [
    "A Multi-Layer Perceptron (MLP) can indeed be viewed as a composition of functions. A typical MLP with three layers can be expressed as a composition of functions representing each layer. Here’s how you can write it:\n",
    "\n",
    "Given:\n",
    "\n",
    "Input vector: $\\mathbf{x}$\n",
    "Weight matrices: $\\mathbf{W}_1, \\mathbf{W}_2, \\mathbf{W}_3$\n",
    "Bias vectors: $\\mathbf{b}_1, \\mathbf{b}_2, \\mathbf{b}_3$\n",
    "Activation functions: $\\sigma_1, \\sigma_2, \\sigma_3$\n",
    "The MLP can be represented as:\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x}) = (f_3 \\circ f_2 \\circ f_1)(\\mathbf{x})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$f_1(\\mathbf{x}) = \\sigma_1(\\mathbf{W}_1 \\mathbf{x} + \\mathbf{b}_1)$\n",
    "\n",
    "$f_2(\\mathbf{z}) = \\sigma_2(\\mathbf{W}_2 \\mathbf{z} + \\mathbf{b}_2)$\n",
    "\n",
    "$f_3(\\mathbf{z}) = \\sigma_3(\\mathbf{W}_3 \\mathbf{z} + \\mathbf{b}_3)$\n",
    "\n",
    "In this formulation, each $f_i$ represents the function of a single layer, including the affine transformation (weight multiplication and bias addition) followed by an activation function. The composition $f = f_3 \\circ f_2 \\circ f_1$ denotes applying these transformations sequentially to compute the output from the input $\\mathbf{x}$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67f8b706-6a11-4ad4-9343-7705e0041e02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d=parse_mol_dict(parse_sdf_file(\"molparser/example.mol\",n=2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bfd82e1-83dd-4460-991d-ccfc433cadb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "densifier=ToDense()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
